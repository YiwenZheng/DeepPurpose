{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/y/home/zyw/tmp/DeepPurpose/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No normalization for BCUT2D_MWHI\n",
      "WARNING:root:No normalization for BCUT2D_MWLOW\n",
      "WARNING:root:No normalization for BCUT2D_CHGHI\n",
      "WARNING:root:No normalization for BCUT2D_CHGLO\n",
      "WARNING:root:No normalization for BCUT2D_LOGPHI\n",
      "WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
      "WARNING:root:No normalization for BCUT2D_MRHI\n",
      "WARNING:root:No normalization for BCUT2D_MRLOW\n"
     ]
    }
   ],
   "source": [
    "from DeepPurpose import utils,dataset,DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Processing...\n",
      "Default set to logspace (nM -> p) for easier regression\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#加载数据\n",
    "X_drug, X_target, y = dataset.load_process_DAVIS('./data/', binary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置编码器\n",
    "drug_encoding = 'CNN'\n",
    "target_encoding = 'Transformer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug Target Interaction Prediction Mode...\n",
      "in total: 30056 drug-target pairs\n",
      "encoding drug...\n",
      "unique drugs: 68\n",
      "encoding protein...\n",
      "unique target sequence: 379\n",
      "splitting dataset...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#分割训练集、验证集和测试集\n",
    "train, val, test = utils.data_process(X_drug, X_target, y, \n",
    "                                drug_encoding, target_encoding, \n",
    "                                split_method='random',frac=[0.7,0.1,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the parameters setting provided in the paper: https://arxiv.org/abs/1801.10193\n",
    "config = utils.generate_config(drug_encoding = drug_encoding, \n",
    "                         target_encoding = target_encoding, \n",
    "                         cls_hidden_dims = [1024,1024,512], \n",
    "                         train_epoch = 100, \n",
    "                         test_every_X_epoch = 10, \n",
    "                         LR = 0.001, \n",
    "                         batch_size = 128,\n",
    "                         hidden_dim_drug = 128,\n",
    "                         mpnn_hidden_size = 128,\n",
    "                         mpnn_depth = 3, \n",
    "                         cnn_target_filters = [32,64,96],\n",
    "                         cnn_target_kernels = [4,8,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型初始化\n",
    "model = DTI.model_initialize(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPU!\n",
      "--- Data Preparation ---\n",
      "--- Go for Training ---\n",
      "Training at Epoch 1 iteration 0 with loss 31.9478. Total time 0.0 hours\n",
      "Training at Epoch 1 iteration 100 with loss 1.06444. Total time 0.02027 hours\n",
      "Validation at Epoch 1 with loss:0.44271, MSE: 0.67488 , Pearson Correlation: 0.41392 with p-value: 8.88260 , Concordance Index: 0.72430\n",
      "Training at Epoch 2 iteration 0 with loss 0.51213. Total time 0.03555 hours\n",
      "Training at Epoch 2 iteration 100 with loss 0.98576. Total time 0.05611 hours\n",
      "Validation at Epoch 2 with loss:0.63264, MSE: 0.64074 , Pearson Correlation: 0.50815 with p-value: 4.08414 , Concordance Index: 0.77269\n",
      "Training at Epoch 3 iteration 0 with loss 0.67944. Total time 0.07166 hours\n",
      "Training at Epoch 3 iteration 100 with loss 0.64542. Total time 0.09194 hours\n",
      "Validation at Epoch 3 with loss:1.20499, MSE: 0.55795 , Pearson Correlation: 0.57305 with p-value: 5.36952 , Concordance Index: 0.78272\n",
      "Training at Epoch 4 iteration 0 with loss 0.43768. Total time 0.1075 hours\n",
      "Training at Epoch 4 iteration 100 with loss 0.85653. Total time 0.12805 hours\n",
      "Validation at Epoch 4 with loss:0.71161, MSE: 0.55341 , Pearson Correlation: 0.60569 with p-value: 1.67865 , Concordance Index: 0.79931\n",
      "Training at Epoch 5 iteration 0 with loss 0.48338. Total time 0.14333 hours\n",
      "Training at Epoch 5 iteration 100 with loss 0.53160. Total time 0.16388 hours\n",
      "Validation at Epoch 5 with loss:0.68115, MSE: 0.49696 , Pearson Correlation: 0.64060 with p-value: 0.0 , Concordance Index: 0.81508\n",
      "Training at Epoch 6 iteration 0 with loss 0.50149. Total time 0.17972 hours\n",
      "Training at Epoch 6 iteration 100 with loss 0.75694. Total time 0.20027 hours\n",
      "Validation at Epoch 6 with loss:0.40308, MSE: 0.50641 , Pearson Correlation: 0.63795 with p-value: 0.0 , Concordance Index: 0.81030\n",
      "Training at Epoch 7 iteration 0 with loss 0.49135. Total time 0.21611 hours\n",
      "Training at Epoch 7 iteration 100 with loss 0.37789. Total time 0.23638 hours\n",
      "Validation at Epoch 7 with loss:0.37765, MSE: 0.47914 , Pearson Correlation: 0.65487 with p-value: 0.0 , Concordance Index: 0.80841\n",
      "Training at Epoch 8 iteration 0 with loss 0.35072. Total time 0.25194 hours\n",
      "Training at Epoch 8 iteration 100 with loss 0.56297. Total time 0.2725 hours\n",
      "Validation at Epoch 8 with loss:0.59958, MSE: 0.49836 , Pearson Correlation: 0.69847 with p-value: 0.0 , Concordance Index: 0.82557\n",
      "Training at Epoch 9 iteration 0 with loss 0.54987. Total time 0.28805 hours\n",
      "Training at Epoch 9 iteration 100 with loss 0.57346. Total time 0.30861 hours\n",
      "Validation at Epoch 9 with loss:0.14792, MSE: 0.41186 , Pearson Correlation: 0.70464 with p-value: 0.0 , Concordance Index: 0.82490\n",
      "Training at Epoch 10 iteration 0 with loss 0.31385. Total time 0.32416 hours\n",
      "Training at Epoch 10 iteration 100 with loss 0.68314. Total time 0.34472 hours\n",
      "Validation at Epoch 10 with loss:0.41090, MSE: 0.45059 , Pearson Correlation: 0.70234 with p-value: 0.0 , Concordance Index: 0.80703\n",
      "Training at Epoch 11 iteration 0 with loss 0.47437. Total time 0.36027 hours\n",
      "Training at Epoch 11 iteration 100 with loss 0.45573. Total time 0.38055 hours\n",
      "Validation at Epoch 11 with loss:0.25424, MSE: 0.41018 , Pearson Correlation: 0.72469 with p-value: 0.0 , Concordance Index: 0.82604\n",
      "Training at Epoch 12 iteration 0 with loss 0.40435. Total time 0.39666 hours\n",
      "Training at Epoch 12 iteration 100 with loss 0.31394. Total time 0.41694 hours\n",
      "Validation at Epoch 12 with loss:0.34868, MSE: 0.41165 , Pearson Correlation: 0.72476 with p-value: 0.0 , Concordance Index: 0.83964\n",
      "Training at Epoch 13 iteration 0 with loss 0.39447. Total time 0.43277 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/y/home/zyw/anaconda3/envs/my-rdkit-env/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/y/home/zyw/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorboard/summary/writer/event_file_writer.py\", line 238, in run\n",
      "    self._record_writer.write(data)\n",
      "  File \"/y/home/zyw/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorboard/summary/writer/record_writer.py\", line 40, in write\n",
      "    self._writer.write(header + header_crc + data + footer_crc)\n",
      "  File \"/y/home/zyw/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py\", line 531, in write\n",
      "    self.fs.append(self.filename, file_content, self.binary_mode)\n",
      "  File \"/y/home/zyw/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py\", line 154, in append\n",
      "    self._write(filename, file_content, \"ab\" if binary_mode else \"a\")\n",
      "  File \"/y/home/zyw/anaconda3/envs/my-rdkit-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py\", line 158, in _write\n",
      "    with io.open(filename, mode, encoding=encoding) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: b'runs/Mar22_10-01-19_n104.yfish.x/events.out.tfevents.1616378479.n104.yfish.x.2084115.0'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存模型\n",
    "model.save_model('./save_model/model_CNN_Transformer_Davis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
